# ğŸµ MoodMusic â€” Facial & Text-Based Mood Music Recommender

A React web app that recommends and plays songs based on the userâ€™s **facial expressions** and/or **typed keywords**.  
Songs are played as embedded videos (YouTube-style) in a playlist interface.

---

## âœ¨ Features

- ğŸ­ Detects facial expressions (happy, sad, angry, surprised, neutral, etc.) using lightweight ML models  
- âŒ¨ï¸ Analyzes text keywords to detect user mood  
- ğŸ”— Combines both signals to recommend mood-based playlists  
- ğŸ“º Embedded video playback, like YouTube  
- ğŸ¨ Styled with Tailwind CSS  

---

## ğŸ› ï¸ Tech Stack

- **React (CRA)** â€” frontend framework  
- **face-api.js** â€” face detection & expression recognition  
- **Tailwind CSS** â€” styling  
- **YouTube Data API** (or other provider) â€” fetch music videos  

---

## ğŸ“‚ Project Structure

